{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\" \n",
    "     width=\"30%\" \n",
    "     align=right\n",
    "     alt=\"Dask logo\">\n",
    "\n",
    "Custom ETL\n",
    "----------\n",
    "\n",
    "This notebook mimics a custom ETL process.  It exemplifies a ubiquitous problem that is both amenable to parallelism and often tricky.\n",
    "\n",
    "It goes through the following steps:\n",
    "\n",
    "1.  Load in several independent datasets\n",
    "2.  Load in a reference dataset\n",
    "3.  Clean each dataset with the reference\n",
    "4.  \"Roll\" the data, considering every triplet dataset in a sliding window\n",
    "5.  Randomly select pairs of these and measure some performance metric\n",
    "6.  Select the best pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build normal Python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from time import sleep\n",
    "\n",
    "def load(address):\n",
    "    sleep(random.random() / 2)\n",
    "    pass\n",
    "\n",
    "def load_from_sql(address):\n",
    "    sleep(random.random() / 2 + 0.5)\n",
    "    pass\n",
    "\n",
    "def process(data, reference):\n",
    "    sleep(random.random() / 2)\n",
    "    pass\n",
    "\n",
    "def roll(a, b, c):\n",
    "    sleep(random.random() / 5)\n",
    "    pass\n",
    "\n",
    "def compare(a, b):\n",
    "    sleep(random.random() / 10)\n",
    "    pass\n",
    "\n",
    "def reduction(seq):\n",
    "    sleep(random.random() / 1)\n",
    "    pass \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate normal Python functions with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "\n",
    "load = delayed(load)\n",
    "load_from_sql = delayed(load_from_sql)\n",
    "process = delayed(process)\n",
    "roll = delayed(roll)\n",
    "compare = delayed(compare)\n",
    "reduction = delayed(reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = ['mydata-%d.dat' % i for i in range(10)]\n",
    "\n",
    "data = [load(fn) for fn in filenames]\n",
    "\n",
    "reference = load_from_sql('sql://mytable')\n",
    "\n",
    "processed = [process(d, reference) for d in data]\n",
    "\n",
    "rolled = []\n",
    "for i in range(len(processed) - 2):\n",
    "    a = processed[i]\n",
    "    b = processed[i + 1]\n",
    "    c = processed[i + 2]\n",
    "    r = roll(a, b, c)\n",
    "    rolled.append(r)\n",
    "    \n",
    "compared = []\n",
    "for i in range(20):\n",
    "    a = random.choice(rolled)\n",
    "    b = random.choice(rolled)\n",
    "    c = compare(a, b)\n",
    "    compared.append(c)\n",
    "    \n",
    "best = reduction(compared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Computation\n",
    "\n",
    "There is clearly parallelism here, but it's not in any standard form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect and Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "\n",
    "client = Client()\n",
    "\n",
    "future = client.compute(best)\n",
    "progress(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = ['mydata-%d.dat' % i for i in range(100)]\n",
    "\n",
    "data = [load(fn) for fn in filenames]\n",
    "\n",
    "reference = load_from_sql('sql://mytable')\n",
    "processed = [process(d, reference) for d in data]\n",
    "\n",
    "rolled = []\n",
    "for i in range(len(processed) - 2):\n",
    "    a = processed[i]\n",
    "    b = processed[i + 1]\n",
    "    c = processed[i + 2]\n",
    "    r = roll(a, b, c)\n",
    "    rolled.append(r)\n",
    "    \n",
    "compared = []\n",
    "for i in range(200):\n",
    "    a = random.choice(rolled)\n",
    "    b = random.choice(rolled)\n",
    "    c = compare(a, b)\n",
    "    compared.append(c)\n",
    "    \n",
    "best = reduction(compared)\n",
    "\n",
    "future2 = client.compute(best)\n",
    "progress(future2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "*  Dask exposes parallelism present in normal code\n",
    "*  Messy problems are common.  It's useful to think without map/filter/groupby/join sometimes."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "265f7ce7520c42f9a098615bd6770b25": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "880f345c62e04073aa862e3a3ab82695": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
